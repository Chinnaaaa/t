from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize

# Define the documents documents = {
"Document 1": "The quick brown fox jumped over the lazy dog", "Document 2": "The lazy dog slept in the sun",
"Document 3": "The quick brown fox and the lazy dog are friends", "Document 4": "The lazy cat watched the lazy dog",
"Document 5": "The quick brown fox ran through the forest"
}

# Step 0: Import NLTK stopwords stopWords = stopwords.words('english')
# Step 1: Tokenize the documents tokens = {}
for doc_id, doc_text in documents.items(): tokens[doc_id] = set(word_tokenize(doc_text.lower()))

# Step 2: Build the inverted index inverted_index = {}
for doc_id, doc_tokens in tokens.items(): for term in doc_tokens:
if term not in stopWords:
if term not in inverted_index: inverted_index[term] = set()
inverted_index[term].add(doc_id)
# Step 3: Document Retrieval System def search_documents(query):
query_terms = set(word_tokenize(query.lower())) - set(stopWords) matching_documents = set()

for term in query_terms:
term_documents = inverted_index.get(term, set()) if not matching_documents:
matching_documents = term_documents else:
matching_documents = matching_documents.intersection(term_documents)
 
return matching_documents

# Step 4: User Input and Query Processing
user_query = input("Enter your query").strip().lower()
matching_docs = search_documents(user_query) if matching_docs:
print(f"\nDocuments containing the terms '{user_query}':
{matching_docs}")
for doc_id in matching_docs:
print(f"{doc_id}: {documents[doc_id]}")
else:
print(f"\nNo documents found for the query '{user_query}'.")
