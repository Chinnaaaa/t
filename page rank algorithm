import numpy as np
def page_rank(graph, damping_factor=0.85, max_iterations=100, tolerance=1e- 6):
"""
Compute PageRank scores for each node in the graph represented by an adjacency list.

Parameters:
-	graph: list of lists, adjacency list representing the graph
-	damping_factor: float, damping factor (default: 0.85)
-	max_iterations: int, maximum number of iterations (default: 100)
-	tolerance: float, tolerance for convergence (default: 1e-6)

Returns:
-	pagerank_scores: numpy array, PageRank scores for each node """
num_nodes = len(graph)
page_ranks = np.ones(num_nodes) / num_nodes

for _ in range(max_iterations): prev_page_ranks = np.copy(page_ranks)

for node in range(num_nodes):
incoming_links = [i for i, v in enumerate(graph) if node in v] if not incoming_links:
continue

page_ranks[node] = (1 - damping_factor) / num_nodes + \
damping_factor * sum(prev_page_ranks[link] / len(graph[link]) for link in incoming_links)
if np.linalg.norm(page_ranks - prev_page_ranks, 2) < tolerance: break
return page_ranks # Example usage
if  name  == " main ":
# Define a simple directed graph as an adjacency list web_graph = [
[1, 2],	# Node 0 has links to Node 1 and Node 2
[0, 2],	# Node 1 has links to Node 0 and Node 2
[0, 1],	# Node 2 has links to Node 0 and Node 1
[1, 2],	# Node 3 has links to Node 1 and Node 2
]
 
# Calculate PageRank
result = page_rank(web_graph)

# Display PageRank values
for i, pr in enumerate(result): print(f"Page {i}: {pr}")
